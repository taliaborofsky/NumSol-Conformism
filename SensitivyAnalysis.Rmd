---
title: "Sensitivity Analysis"
author: "Talia Borofsky"
date: "5/31/2020"
output:
  html_document: default
  pdf_document: default
---
TO-DO: 
- Rerun, noting that if sign(C_s) < 0 when K = 0, this does not mean decreased social learning invades
- Why was C_s actually negative in those 16 places?
- Why did I know they're actually stable for this line: "fix equilibria in which lambdastar = 1 but actually internally stable"?
    Why are equilibria for the mask (beta==0)&(D==0)&(pc==0)&(K>0) actually stable?
    If we iterated to the equilibria then they're stable. But what if we didn't iterate to the equilibrium?
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(stargazer)
library(car)
library(dplyr)
library(aod)
library(ggplot2)
library(latex2exp)
library(olsrr)
library(lmtest)
library(zeallot)
library(ROSE) # for roc curve
library(RVAideMemoire) # library that has spearman.ci function...gets confidence intervals on spearman using bootstrap

figure_folder = "/Users/taliaborofsky/Documents/Stanford/Research/Feldman/Ecology of Learning/Conformism/Paper_to_Submit_EcoMono2/"
```

# K > 1/2, D = 0, unequal equilibrium
$$
\text{sign}(C_D) = \text{sign} \left( \frac{2K-1}{K} -3 \left(u_1^2 + \left( \frac{2K-1}{K} - u1 \right)^2 \right)+2 \left(u_1^3 + \left( \frac{2K-1}{K} - u1 \right)^3 \right)\right)
$$

Figure 3: Looking at what values of $K$ and $\hat{u}_1$ will allow anti-conformity ($C_D < 0$) or conformity ($C_D > 0$) to invade when there is no social learning, individual learning is always wrong, resources are unlimited ($K = \pi_C = \beta = 0$), when $\hat{u}_1 + \hat{u}_2 = \frac{2K -1}{K}$. 

```{r}

grid <- expand.grid(K = seq(1/2,0.99,length.out=1000),u = seq(0,1,length.out=1000))
f <- function(K,u) (2*K-1)/K -3*u^2 -3*((2*K-1)/K -u)^2 + 2*u^3 + 2*((2*K-1)/K -u)^3
f2 <- function(K,u) (2*K-1)/K - u
grid$filled <- (f(grid$K,grid$u)>=0) 
grid$filled[(f2(grid$K,grid$u)<0)|(f2(grid$K,grid$u)>1)] = NA
p<- ggplot(grid) + geom_tile(aes(x=K,y=u,fill=filled))  + theme_classic() + labs(x=TeX("$K$"),y = TeX("$\\hat{u_1}$"))+ theme(legend.position = "none") + scale_fill_brewer(palette="Set1", na.value="white") + theme(text = element_text(size = 20)) 

p
fn = "D0Unequal_C_D.png"
ggsave(file.path(figure_folder, fn), plot = p)
#red means C_D < 0, turquoise means C_D > 0
```


The rest of this Rmd file deals with numerical analysis.

First, we load the main dataframe from 'UniqueEquilibriaDF.csv' which was generated in GenerateDFs.ipynb. It contains equilibria that were achieved through iteration. An overview of the columns:
- The model's parameter values are stored in the K, pc, s, mu, D, and beta columns. 
- The equilia frequencies are in the u1eq, u2eq, bueq, r1eq, r2eq columns
- The equilibrium mean population fitness value is the Weq column
- indicators of stability are: C_s, C_D, difference, y_neg_invades, y_pos_invades, x_neg_invades, x_pos_invades
     - C_s, C_D are calculated from Eqs. 19 and 20 respectively.Their signs indicate whether the equilibrium is unstable to an increase or decrease in social learning and conformity, respectively. However, we have to be careful when $K$ or $D$ are at their boundaries, e.g. when $K = 0$, $C_s < 0$ means that the equilibrium is stable rather than that allele $a$ with negative social learning (which is impossible) will invade. Another issue with this column is we don't know whether social learning or conformity levels are stable if $C_s = 0$ or $C_D = 0$, respectively. 
     - y_neg_invades y_pos_invades, x_neg_invades, x_pos_invades corrects for the issue just mentioned in the last bullet. We corrected for boundary cases and if $C_s = 0$ or $C_D = 0$, we perturb the equilibrium in the $x$ or $y$ direction, respectively for both signs of $\delta_s$ and $\delta_D$, respectively. 
         - y_neg_invades --> allele $b$ with $\delta_{D} < 0$ invades (TRUE if invades, FALSE if doesn't invade)
         - y_pos_invades --> allele $b$ with $\delta_{D} > 0$ invades (TRUE if invades, FALSE if doesn't invade)
         - x_neg_invades --> allele $a$ with $\delta_{s} < 0$ invades (TRUE if invades, FALSE if doesn't invade)
         - x_pos_invades --> allele $a$ with $\delta_{s} > 0$ invades (TRUE if invades, FALSE if doesn't invade).

```{r dframes, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# load the Unique Equilibria

uniqueEquilibria <- read.csv('UniqueEquilibriaDF_fixed.csv', as.is=TRUE)


# helped to round D values
uniqueEquilibria$D <-round(uniqueEquilibria$D,digits = 10)

# Adjusting bool strings to actual R bool values
uniqueEquilibria[uniqueEquilibria=="True"]=TRUE
uniqueEquilibria[uniqueEquilibria=="False"]=FALSE
### deal with equilibria for which lambda* = 1

# rename and do rest of changes to eqData
eqData <- uniqueEquilibria

# label by type of invasion that can happen. In combines the x_pos_invades with x_neg_invades, and the y_pos_invades with y_neg_invades
eqData$a_stability <- "zero"
eqData$a_stability[eqData$x_pos_invades==TRUE & eqData$x_neg_invades==FALSE] <- "positive"
eqData$a_stability[eqData$x_neg_invades==TRUE & eqData$x_pos_invades==FALSE] <- "negative"
eqData$a_stability[eqData$x_pos_invades==TRUE & eqData$x_neg_invades==TRUE] <- "both"
eqData$a_stability <- factor(eqData$a_stability)

eqData$b_stability <- "zero"
eqData$b_stability[eqData$y_pos_invades==TRUE & eqData$y_neg_invades==FALSE] <- "positive"
eqData$b_stability[eqData$y_neg_invades==TRUE & eqData$y_pos_invades==FALSE] <- "negative"
eqData$b_stability[eqData$y_pos_invades==TRUE & eqData$y_neg_invades==TRUE] <- "both"
eqData$b_stability <- factor(eqData$b_stability)

# It'll help to know dk, dpc, lambda_x, lambda_y values, and keep track of where linear external stability analysis is inconclusive
x_local_inconclusive = abs(eqData$C_s)<0.001 & (eqData$a_stability == "both" | eqData$a_stability == "zero")
eqData$x_local_inconclusive = x_local_inconclusive
eqData$y_local_inconclusive = abs(eqData$C_D)<0.001 & (eqData$b_stability == "both" | eqData$b_stability == "zero") 


phi_fun <- function(p) p*(1-p)*(2*p-1)
find_K <- function(mu,s) pnorm(s,mean=mu,sd=1) - pnorm(-s,mean=mu,sd=1)
find_pc <- function(mu,s) 1 - pnorm(s, mean = mu, sd = 1)
find_dk <- function(mu,s,ds) find_K(mu,s+ds) - find_K(mu,s)
find_dpc <- function(mu,s,ds) find_pc(mu,s+ds) - find_pc(mu,s)
find_lambdax <- function(dpc, dk, D, u1eq, u2eq, r1eq, r2eq, Weq){
  lambdax = 1 + (1/Weq)*(dpc + r1eq*(dk*u1eq + dk*D*phi_fun(u1eq) + dpc)
                         + r2eq*(dk*u2eq + dk*D*phi_fun(u2eq) + dpc))
  return(lambdax)
}
find_lambday <- function(dD, C_D){
  lambday = 1 + dD*C_D
  return(lambday)
}
eqData = eqData %>% mutate(dk_pos = find_dk(mu,s,0.01), 
                           dpc_pos = find_dpc(mu,s,0.01), 
                           dk_neg = find_dk(mu,s,-0.01), 
                           dpc_neg = find_dpc(mu,s,-0.01)
                           ) %>% mutate( 
                            lambda_x_pos = find_lambdax(dpc_pos,dk_pos,D, u1eq,u2eq,r1eq,r2eq,Weq),
                            lambda_x_neg = find_lambdax(dpc_neg, dk_neg, D, u1eq, u2eq, r1eq, r2eq, Weq),
                            lambda_y_pos = find_lambday(0.01,C_D),
                            lambda_y_pos = find_lambday(-0.01,C_D)
                           )
# remove values where s = 0 and D != 0 because we assume an organism can't have the conformist transmission bias trait 
# without being able to leran socially
eqData <- eqData %>% filter(!(s==0&D!=0))

# below was in the code for the first draft but we have since determined that it's unnecessary and 
# can actually erroneously set cases where beta = 0, D = 0, pc = 0, and K>1/2 as stable
  # # fix equilibria in which lambdastar = 1 but actually internally stable
  # attach(eqData)
  # mask =(beta==0)&(D==0)&(pc==0)&(K>0) # this equilibria might have lambda* = 1, but is actually internally stable
  # eqData[mask,]$URstable = 1
  # detach(eqData)


  # only use equilibria that are internally stable
  # no longer necessary because I'm only using equilibria that were arrived at through iteration: eqData <- eqData %>% filter(URstable == 1)

# # (NO LONGER NECESSARY)If C_s is negative when K = 0, then set it to 0
  #eqData[(eqData$K==0)&(eqData$C_s<0),]$C_s = 0

# label by the sign of C_s
eqData$signC_s <- factor(sign(eqData$C_s))

# (Fixed. NO LONGER NECESSARY) thre are about 16 places where r says C_s = 0 but it's actually negative
  # eqData$signC_s[eqData$signC_s==0] = -1

# label by the sign of C_D
eqData$signC_D <- factor(sign(eqData$C_D))



# add column for learning success 
eqData$learningSuccess = eqData$u1eq + eqData$u2eq # portion of foragers that learn how to find food


# Make separate data frames for whether D \geq 0 or D \leq 0 and for whether or not u1 = u2
eqDataPos = eqData %>% filter(D>=0)
eqDataPos_UnEqual <-  eqDataPos %>% filter(difference > 0)
eqDataPos_Equal = eqDataPos %>% filter(difference==0)
# D < 0
eqDataNeg = eqData %>% filter(D<0)
eqDataNeg_UnEqual = eqDataNeg %>% filter(difference>0)
eqDataNeg_Equal = eqDataNeg %>% filter(difference==0)


```

# Numerical Analysis
## Data
The dataframes I work with are:

* *eqData* - the dataframe of all the parameter and equilibrium combinations that are internally stable
* *eqDataPos* - the dataframe of all the parameter and equilibrium combinations that are internally stable such that $D \geq 0$
* *eqDataNeg* -  the dataframe of all the parameter and equilibrium combinations that are internally stable such that $D < 0$
* *eqDataPos_Equal* - eqDataPos, but only the equilibria in which $|\hat{u_1} - \hat{u_2}| = 0$. 
* *eqDataPos_UnEqual* - eqDataPos, but only the equilibria in which $|\hat{u_1} - \hat{u_2}| > 0$. -

The important new columns of the dataframes are:

* difference ($|\hat{u_1} - \hat{u_2}|$)
* learningSuccess ($\hat{u_1} + \hat{u_2}$)
* a_stability
    * 0 if x_pos_invades = x_neg_invades = FALSE
    * 1 if x_pos_invades = TRUE
    * -1 if x_neg_invades = TRUE
* b_stability - like a_stability but for b
s


## Numerical Results 6.1 The effect of anti-conformity and conformity on learning success and mean population fitness
In this section, we seek to understand what advantage anticonformity confers. We use Spearman's rank correlation coefficient to examine the relationships between anti-conformity and mean population fitness, $\hat{W}$, and learning success, $\hat{u_1} + \hat{u_2}$, without accounting for social learning $K$.

The linear regression of $D: D < 0$ onto both $\hat{W}$ and learning success $\hat{u_1} + \hat{u_2}$ has $R^2 < .01$.

```{r anticonformity W learning success spearman, echo=FALSE, warning=FALSE, message=FALSE}
print('Anti-conformity and W')
# want for D <= 0, so create eqData_nonNeg
eqData_nonNeg = eqData %>% filter(D <= 0)
corWeq <- cor.test(eqData_nonNeg$D, eqData_nonNeg$Weq, method = "spearman"); print(corWeq)
print('Anti-conformity and learning success')
corlearn <- cor.test(eqData_nonNeg$D, eqData_nonNeg$learningSuccess, method = "spearman"); print(corlearn)
set.seed(5)
spearman.ci(eqDataNeg$D, eqDataNeg$learningSuccess, nrep = 1000, conf.level = 0.985) # use conf.level = 0.995 because 0.999
```



For comparison, look at how conformity affects these values. We use eqDataPos for the correlation, for which $D \geq 0$.
```{r}
#mpos <- lm(data=eqDataPos, Weq ~ D)
#summary(mpos)

cor.test(eqDataPos$Weq, eqDataPos$D, method = "spearman")
set.seed(5)
spearman.ci(eqDataPos$D, eqDataPos$Weq, nrep = 1000, conf.level = 0.999)

cor.test(eqDataPos$learningSuccess, eqDataPos$D, method = "spearman")
set.seed(5)
spearman.ci(eqDataPos$D, eqDataPos$learningSuccess, nrep = 1000, conf.level = 0.999)

```

## Section 6.2: Positive feedback between the evolution of social learning and learning success
First, does more social learning correspond with more learning success (regardless of $\pi_c$)?

We try a linear regression of $K$ on learning success $\hat{u_1} + \hat{u_2}$

```{r sec3 lin reg, echo=FALSE, warning=FALSE, message=FALSE}

m1 <- lm(learningSuccess ~ K, data = eqData)
summary(m1)

```
Social learning seems to correlate with more learning success, though the relationship is not linear.
Since the relationship is not linear, we try a spearman rank correlation
```{r sec3 spearman, echo=FALSE, warning=FALSE, message=FALSE}
ctest <- cor.test(eqData$K, eqData$learningSuccess, method = "spearman")
ctest
set.seed(5)
spearman.ci(eqData$K, eqData$learningSuccess, nrep = 1000, conf.level = 0.999)

```

We see a strong and significant positive correlation ($\rho = .483, p < .001$)


We can look at whether learning success values are distributed differently when $C_s >0$, $C_s = 0$, and $C_s < 0$.

```{r}
#attach(eqData)
eqData_use = eqData %>% filter(!x_local_inconclusive)





#maxs$Tukey = c('a','b','c')
p.b <- ggplot(data=eqData_use, aes(x=signC_s,y=learningSuccess,fill=signC_s))+geom_violin(adjust=1) + theme_classic() + labs(x=TeX("\nSign of $C_s$"), fill = TeX("$sign of $C_s$"), y = TeX("\\hat{u_1} + \\hat{u_2}"),fontsize=20) + theme(legend.position = "none") + theme(text = element_text(size = 20)) 

p.b
fn = "LearnSuccess_SignCs.png"
#ggsave("LearnSuccess_SignCs.png", plot = p.b)
ggsave(file.path(figure_folder, fn), plot = p.b)
p.his <- ggplot(data=eqData_use, aes(x=learningSuccess))+geom_histogram(binwidth=.01) + theme_classic() + theme(text = element_text(size = 20)) + labs(x = "Learning Success")
p.his
fn = "LearnSuccess_his.png"
ggsave(file.path(figure_folder,fn), plot = p.his)

```
Thus increased social learning tends to invade when learning success is high, especially when $\hat{u_1} + \hat{u_2} = 1$, while the learning success at equilibria for which decreased social learning envades has a bimodal distribution: learning success is either high or low. Furthermore, $C_s \new 0$ for all equilibria in which $K = 0$. 

These trends are slightly different when we analyze equal and unequal equilibria separately. Here are the violin plots when $\hu{1} = \hu{2}$ and $D \geq 0$. I specify $D \geq 0$ because we want to compare the equal and unequal equilibria cases, but equilibria are only unequal when $D \geq 0$. Each violin is labeled with the number of equilibria it describes.
```{r}
abs_max = max(learningSuccess)
maxs <- eqDataPos_Equal %>% group_by(a_stability ) %>% summarise(learningSuccess=max(learningSuccess) + 0.05 * abs_max, n = length(a_stability)) 


p.b <- ggplot(data=eqDataPos_Equal, aes(x=a_stability,y=learningSuccess, fill = a_stability))+geom_violin(adjust=1) + theme_classic() + labs(x=TeX("$sign(\\delta_s)$"), fill = TeX("$sign(\\delta_s)$"), y = TeX("maximum \\hat{u_1} + \\hat{u_2}"),fontsize=20)+ geom_text(data=maxs,aes(label=n))

p.b
```
Here are violin when $\hu{1} \neq \hu{2}$ and $D \geq 0$. 
```{r}
abs_max = max(learningSuccess)
maxs <- eqDataPos_UnEqual %>% group_by(a_stability ) %>% summarise(learningSuccess=max(learningSuccess) + 0.05 * abs_max, n = length(a_stability))


p.b <- ggplot(data=eqDataPos_UnEqual, aes(x=a_stability,y=learningSuccess, fill = a_stability))+geom_violin(position=position_dodge(1)) + theme_classic() + labs(x=TeX("$sign(\\delta_s)$"), y = TeX("\\hat{u_1} + \\hat{u_2}"),fontsize=20)+ geom_text(data=maxs,aes(label=n)) + ylim(0,1.3)

p.b

p.his <- ggplot(data=eqDataPos_UnEqual, aes(x=learningSuccess))+geom_histogram(binwidth=.01) + theme_classic()
p.his
```

$C_s \neq 0$ for all equilibria in which $\hu{1} \neq \hu{2}$. Less social learning only invades when $\hu{1} + \hu{2}$ is high., but also most of the equilibria in which $\hu{1} \neq \hu{2}$ have high learning success.


Next, we predict that if it is harder to learn individually correctly, then social learning should be even more beneficial to learning success. We use the indicator variable mu_pos, which is 1 when $\mu \geq 0$ and 0 otherwise and do a linear regression of the effect of the interaction between $K$ and mu_pos on learning success.

```{r sec3 mu, echo=FALSE, warning=FALSE, message=FALSE}
# still have eqData attached

mu_pos = eqData$mu>=0
eqData$mu_pos = mu_pos
m.mu <- lm(learningSuccess ~K*mu_pos, data=eqData)
summary(m.mu)
stargazer(m.mu, type="text")
c(m.int, m.K, m.mu_pos, m.mu_pos.K) %<-% m.mu$coefficients
```
So when $\mu \geq 0$,
$$
\hat{u_1} + \hat{u_2} = .934 + 0.002K
$$
and when $\mu < 0$,
$$
\hat{u_1} + \hat{u_2} = .227 + .619 K
$$
although the $R^2 - .479$, which is rather low.

Now how does $\mu$ affect whether learning success selects for social learning? Again use the indicator variable mu_pos. Then Chi-squared test of independence to examine whether the evolution of social learning is related to the sign of mu:

```{r chi-squared, warning=F,message=F}
# mupos is 1 if > 0, 0 if <=0
eqData_use = eqData %>% filter(!x_local_inconclusive)
mu_nonneg = factor(eqData_use$mu>=0)
signC_s = eqData_use$signC_s
SocLearnMuTable <- table(signC_s, mu_nonneg)
SocLearnMuTable


chisq.test(SocLearnMuTable)


datuse <- data.frame(mu_nonneg, signC_s)
datuse <- datuse %>% group_by(mu_nonneg, signC_s) %>% count()

p <- ggplot(datuse, aes(x = mu_nonneg, y = n, fill = signC_s)) + geom_bar(position="stack",stat="identity") + labs(y="Num Equilibria", fill = TeX("$sign(C_s)$"), x = TeX("$\\mu \\geq 0$")) + theme_classic()+ theme(text = element_text(size = 20)) 
p
fn = "MuSocLearnStack.png"
ggsave(file.path(figure_folder,fn), plot = p)
```


## Section 3: The effects of social learning and conformity on behavioral preference

I hypothesized that social learning ($K$), conformity ($D$), and in particularly the product of the two ($KD$) should cause larger behavioral preference $$ |\hat{u_1} - \hat{u_2}|$$. 
In this case behavioral preference was measured from the equilibrium that had the maximum $$\mid \hat{u_1} â€“ \hat{u_2} \mid $$ for each set of parameters.
Doing a linear regression of behavioral preference in relation to $K$, $D$, and $KD$, the coefficients are described in the following table:

```{r sec4, echo=FALSE, warning=FALSE, message=FALSE}
#eqdata already attached
eqData.maxDiff <- eqDataPos %>%
  group_by(s,K,D,mu,beta) %>%
  summarise(max_diff = max(difference)) %>% 
  mutate(KD = K*D)

attach(eqData.maxDiff)
m <- lm(max_diff ~ K*D, data=eqData.maxDiff)
summary(m)
stargazer(m, type = "text", covariate.labels = c("K","D", "KD"), dep.var.labels = "Maximum Behavioral Preference")
plotH2 <- ggplot(data = eqData.maxDiff, mapping = aes(x = KD, y = max_diff)) + geom_point(size = 3, shape = 1) + theme_bw()
plotH2 <- plotH2 + labs(x = TeX("$KD$"), y = "Max Behavioral Preference")  
plotH2
#mypath = file.path(paste("/Users/taliaborofsky/Documents/Stanford/Research/Feldman/Ecology of Learning/Conformism/Paper_to_Submit_EcoMono2","plotH2.png"))
#ggsave(mypath, plot = plotH2) # still calling it H2 because when I originally named these plots I called this section was hypothesis 2
```
Social learning has  a positive effect as expected, but conformity has a negative effect, which is weird. Finally, as expected, social learning and conformity together increase behavioral preference more then social learning alone. 

## Section 6.4: The effects of food depletion and behavioral preference on learning success and mean population fitness.

I expected that increasing predation, $\beta$, would suppress learning success $\hat{u_1} + \hat{u_2}$ , 
and for this effect to be amplified by behavioral preference $|\hat{u_1} - \hat{u_2}|$.


I check the effect of $\beta$ and its interaction with an indicator variable called "isDiff" that is 1 when $\hat{u_1} \neq \hat{u_2}$, 0 otherwise. *

Below, I look at a linear regression. However, the $R^2$ value is too low.
```{r sec5, echo=FALSE, warning=FALSE, message=FALSE}

attach(eqData)
isDiff = difference > 0
m1 <- lm(Weq ~ isDiff*beta)
print(summary(m1))
c(m1.int, m1.isDiff, m1.beta, m1.isDiff.beta) %<-% m1$coefficients
stargazer(m1, type = "text",covariate.labels = c("isDiff=TRUE", "beta", "beta(isDiff=TRUE)"), dep.var.labels = "Mean Pop Fitness")
library(ggplot2)


datUse = eqDataPos %>% mutate(betadiff = beta*difference)
plotH1.LS <- ggplot(data = datUse, mapping = aes(x = difference, y = learningSuccess, color = beta)) + geom_point(size = 3, alpha = 0.5) + theme_bw()+ labs(x = TeX("$|\\hat{u_1} - \\hat{u_2}|$"), y = TeX("$\\hat{u_1} + \\hat{u_2}$"), color = TeX("$\\beta$")) + theme(text = element_text(size = 20)) 
plotH1.LS
#fn = "Figures/plotH1_LS.png"
#ggsave(file.path(figure_folder,fn), plot = plotH1.LS)
```


As for learning success, a linear regression with isDiff and beta as covariates also has a poor fit:
```{r sec5 ls, echo=FALSE, warning=FALSE, message=FALSE}
m2 <- lm(learningSuccess ~ isDiff*beta)
c(m2.int, m2.isDiff, m2.beta, m2.isDiff.beta) %<-% m2$coefficients
stargazer(m2, type = "text",covariate.labels = c("isDiff=TRUE", "beta", "beta(isDiff=TRUE)"), dep.var.labels = "Learning Success")



plot.H1.W <- ggplot(data = datUse, mapping = aes(x = difference, y = Weq, color = beta)) + geom_point(size=3, alpha = 0.5) + theme_bw() + labs(x = TeX("$|\\hat{u_1} - \\hat{u_2}|$"), y = TeX("$\\hat{W}$"), color = TeX("$\\beta$")) 
plot.H1.W
#ggsave("Figures/plotH1_W.png", plot = plot.H1.W)

```

Next, look at correlations.

Correlations when $\hu{1} = \hu{2}$
```{r, message=F}
attach(eqData)
isDiff = difference > 0
cor.test(eqData$Weq[!isDiff],eqData$beta[!isDiff], method = "spearman")
set.seed(5)
spearman.ci(eqData$Weq[!isDiff],eqData$beta[!isDiff],nrep=1000,conf.level=0.999)


cor.test(eqData$Weq[isDiff], eqData$beta[isDiff], method = "spearman")
set.seed(5)
spearman.ci(eqData$Weq[isDiff],eqData$beta[isDiff],nrep=1000,conf.level=0.999)
```

The relationship between $\beta$ and learning success
```{r, message=F}
attach(eqData)

isDiff = difference > 0

cor.test(eqData$learningSuccess[!isDiff],eqData$beta[!isDiff], method = "spearman")

cor.test(eqData$learningSuccess[isDiff], eqData$beta[isDiff], method = "spearman")
spearman.ci(eqData$learningSuccess[isDiff], eqData$beta[isDiff],nrep=1000,conf.level=0.999)
```
## Section 5: Food depletion and behavioral preference

Test (H4): an increased rate of resource utilization would lower behavioral preference
```{r sec6 depletion and behavior pref, echo=FALSE, warning=FALSE, message=FALSE}

m <- lm(data = eqData, difference ~ beta)
stargazer(m, type = "text", dep.var.labels = "behavioral preference") # linear regression doesn't fit

cortest <- cor.test(eqData$beta, eqData$difference, method = "spearman")
cortest
set.seed(5)
spearman.ci(eqData$beta, eqData$difference, nrep = 1000, conf.level = 0.999)
```
For the linear model, the $R^2$ is too low. I use Spearman's rank instead, and find the correlation between $\beta$ and behavioral preference is $\rho = `r cortest$estimate`, p = `r cortest$p.value`$. The $\rho$ value is close to the coefficient of $\beta$ in the linear model, and I'm wondering if I can still use the linear model to say that increasing predation $\beta$ makes the population show less behavioral preference.

## Section 6: Food depletion hampers the evolution of social learning and conformity
```{r D0}
eqDataD0 <- eqData %>% filter(D==0 & !x_local_inconclusive)
eqDataD0$mu_pos <- eqDataD0$mu >=0

set.seed(5)
eqDataD0_muPos <- eqDataD0 %>% filter(mu_pos==TRUE)
eqDataD0_muNeg <- eqDataD0 %>% filter(mu_pos==FALSE)
print("Correlation between Cs and beta when D = 0")
cortest <- cor.test(eqDataD0$C_s, eqDataD0$beta, method="spearman")
cortest
spearman.ci(eqDataD0$C_s, eqDataD0$beta, nrep = 1000, conf.level=0.98)
set.seed(5)
print("Correlation between Cs and beta when D = 0 and mu >= 0")
cortest1 <- cor.test( eqDataD0_muPos$C_s, eqDataD0_muPos$beta, method = "spearman")
cortest1
spearman.ci(eqDataD0_muPos$beta, eqDataD0_muPos$C_s, nrep = 1000, conf.level = 0.95)
set.seed(5)
print("Correlation between Cs and beta when D = 0 and mu < 0")
cortest2 <- cor.test( eqDataD0_muNeg$C_s, eqDataD0_muNeg$beta, method = "spearman")
cortest2
spearman.ci(eqDataD0_muNeg$beta, eqDataD0_muNeg$C_s, nrep = 1000, conf.level = 0.95)

p <- ggplot(data = eqDataD0, aes(x=beta,y=C_s,color=mu_pos )) + geom_jitter() + geom_smooth(method=lm,se=FALSE, fullrange=TRUE) + theme_classic()  + labs(x=TeX("$\\beta$"), y=TeX("$C_s$"), colour = TeX("$\\mu \\geq 0$"),fontsize=20) + scale_color_manual(breaks = c(FALSE, TRUE),values=c("red", "#56B4E9")) + geom_hline(yintercept=0,linetype="dashed", size=0.5)+ theme(text = element_text(size = 20)) 
p
fn = "D0jitter.png"

ggsave(file.path(figure_folder,fn), plot = p)

eqDataD0_x_pos <- eqDataD0 %>% filter(x_pos_invades==TRUE)
nrow(eqDataD0)
nrow(eqDataD0_x_pos)
max(eqDataD0_x_pos$beta)
```
```{r}
eqData_use <- eqData %>% filter(!x_local_inconclusive & mu <= 0)
eqData_use$isDiff = eqData_use$difference>0
p.b <- ggplot(data=eqData_use, aes(x=factor(x_pos_invades),y=beta,fill=isDiff))+geom_boxplot(adjust=1, scale = "count") + theme_classic() + labs(x="Increased Social Learning Invades", y = TeX("$\\beta$"),fontsize=20)+ theme(text = element_text(size = 20),axis.title.x = element_text(vjust=-0.8))  #+ geom_text(data=maxs,aes(label=Tukey))

p.b <- p.b + scale_fill_discrete(name = "Behavioral Preference", labels = c("no behavioral preference","positive behavioral preference"))
p.b
#ggsave(file.path(figure_folder,"BehavPref_boxplot.png"), plot = p.b)

p.b2 <- ggplot(data = eqData_use, aes(x = factor(x_pos_invades), y = difference, fill = factor(x_pos_invades))) + geom_violin(adjust=1, scale = "count") + theme_classic() + labs(x = "Increased Social Learning Invades", y = TeX("$|\\hat{u}_1 - \\hat{u}_2|"), fontsize = 22)+ theme(text = element_text(size = 20),axis.title.x = element_text(vjust=-0.8))+ theme(legend.position = "none")

p.b2
#ggsave(file.path(figure_folder,"BehavPref_nobeta_violin.png"), plot = p.b2)

```
When D is not restricted to D = 0, I'll look at box

```{r}
eqData_use <- eqData %>% filter(!x_local_inconclusive)
mylogit <- glm(data = eqData_use,  factor(x_pos_invades)~ beta * difference, family = "binomial")
summary(mylogit)

ggplot(data=eqData_use, aes(x=beta, y = difference^2)) + geom_jitter(aes(color = factor(signC_s)))
```

```{r}

#maxs$Tukey = c('a','b','c')
eqData_use <- eqData %>% filter(!x_local_inconclusive)
eqData_use$isDiff = eqData_use$difference>0
p.b <- ggplot(data=eqData_use, aes(x=factor(x_pos_invades),y=beta,fill=isDiff))+geom_boxplot(adjust=1, scale = "count") + theme_classic() + labs(x="Increased Social Learning Invades", y = TeX("$\\beta$"),fontsize=20)+ theme(text = element_text(size = 20),axis.title.x = element_text(vjust=-0.8))  #+ geom_text(data=maxs,aes(label=Tukey))

p.b <- p.b + scale_fill_discrete(name = "Behavioral Preference", labels = c("no behavioral preference","positive behavioral preference"))
p.b
ggsave(file.path(figure_folder,"BehavPref_boxplot.png"), plot = p.b)

p.b2 <- ggplot(data = eqData_use, aes(x = factor(x_pos_invades), y = difference, fill = factor(x_pos_invades))) + geom_violin(adjust=1, scale = "count") + theme_classic() + labs(x = "Increased Social Learning Invades", y = TeX("$|\\hat{u}_1 - \\hat{u}_2|"), fontsize = 22)+ theme(text = element_text(size = 20),axis.title.x = element_text(vjust=-0.8))+ theme(legend.position = "none")

p.b2
ggsave(file.path(figure_folder,"BehavPref_nobeta_violin.png"), plot = p.b2)
# aov <- aov(beta ~ signC_s*isDiff)
# summary(aov)
# 
# aov1 <- aov(beta~ factor(isDiff), subset=signC_s==1)
# summary(aov1)
# TukeyHSD(aov1)
```


```{r stats for figs 9,10}
attach(eqDataPos)
isDiff = difference>0
colnames(eqDataPos)
dat = eqDataPos %>% filter(difference>0)
mod <- aov(dat$beta ~ factor(dat$y_pos_invades))
summary(mod)
TukeyHSD(mod)

modsoc <- aov(data=eqDataPos, beta ~ factor(x_pos_invades))
summary(modsoc)
TukeyHSD(modsoc)
aov1 <- aov(beta~ factor(isDiff), subset=signC_s==1)
summary(aov1)
TukeyHSD(aov1)


```

```{r}

attach(eqDataPos)
isDiff = difference>0

dat = eqDataPos %>% filter(difference>0 & !y_local_inconclusive)

p.b <- ggplot(data=dat, aes(x=factor(y_pos_invades),y=beta))+geom_boxplot() + theme_classic() + labs(x="Increased Conformity Evolves", y = TeX("$\\beta$"),fontsize=20) + theme(text = element_text(size = 20),axis.title.x = element_text(vjust=-1.1)) #+ geom_text(data=maxs,aes(label=Tukey))

p.b

fn = "BehavPref_boxplot_D.png"
ggsave(file.path(figure_folder,fn), plot = p.b)

p.b <- ggplot(data=dat, aes(x=factor(y_neg_invades),y=beta))+geom_boxplot() + theme_classic() + labs(x="Decreased Conformity Evolves", y = TeX("$\\beta$"),title = TeX("$\\hat{u_1} \\neq \\hat{u_2}$"),fontsize=20) + theme(text = element_text(size = 20),axis.title.x = element_text(vjust=-1.1)) #+ geom_text(data=maxs,aes(label=Tukey)) 

p.b
fn = "BehavPref_boxplot_pos_diff_Dless.png"
ggsave(file.path(figure_folder,fn), plot = p.b)

p.b <- ggplot(data=eqData %>% filter(difference==0), aes(x=factor(y_neg_invades),y=beta))+geom_boxplot() + theme_classic() + labs(x="Decreased Conformity Evolves", y = TeX("$\\beta$"), title = TeX("$\\hat{u_1} = \\hat{u_2}$"),fontsize=20) + theme(text = element_text(size = 20),axis.title.x = element_text(vjust=-1.1)) #+ geom_text(data=maxs,aes(label=Tukey))

p.b
fn = "BehavPref_boxplot_pos_nodiff_Dless.png"
ggsave(file.path(figure_folder,fn), plot = p.b)


# aov <- aov(beta ~ factor(signC_D)*factor(isDiff))
# summary(aov)
# aov1 <- aov(beta~signC_D)
# TukeyHSD(aov1)
# aov2 <- aov(beta~signC_D, subset=isDiff) #when hu1 \neq hu2
# aov3 <- aov(beta~signC_D, subset=!isDiff) #when hu1 = hu2
# t <- TukeyHSD(aov)
# t$`factor(signC_D):factor(isDiff)`
# plot(t$`factor(signC_D):factor(isDiff)`)


```


To-do: Do D < 0 and D > 0 separately

```{r }
#detach("package:plotly", unload = TRUE)
library(ggplot2)
library(ggtern)
library(latex2exp)
library("viridis")




# C_s --> actually uses a_stability
datUse_C_s <- eqDataPos %>% filter(!x_local_inconclusive)
plotC_s <- ggplot(data = datUse_C_s, mapping = aes(x = u1eq, y = u2eq, z = bueq)) + coord_tern(Tlim=c(0,1),Llim=c(0,1),Rlim=c(0,1)) + geom_point(aes(colour = signC_s), size = 5, alpha = 0.8, shape = 1) + theme_bw()
plotC_s <- plotC_s + tern_limits(labels=c(0,0.2, 0.4, 0.6, 0.8, 1)) + labs(x = TeX("$u_1$"), y = TeX("$u_2$"), z = TeX("$\\bar{u}$"),color = TeX("$sign(C_s )$")) +theme_legend_position(x = "topleft")  + theme(plot.margin=grid::unit(c(0,0,0,0), "mm"))  + theme(text = element_text(size = 18))
plotC_s
ggsave(file.path(figure_folder,"ternaryAll_C_s.png"), plot = plotC_s)

#C_D

datUse_C_D <- eqDataPos %>% filter(!y_local_inconclusive)
plotC_D <- ggplot(data = datUse_C_D, mapping = aes(x = u1eq, y = u2eq, z = bueq)) + coord_tern(Tlim=c(0,1),Llim=c(0,1),Rlim=c(0,1)) + geom_point(aes(colour = signC_D), size = 5, alpha = 0.8, shape = 1) + theme_bw()
plotC_D <- plotC_D + tern_limits(labels=c(0,0.2, 0.4, 0.6, 0.8, 1)) + labs(x = TeX("$u_1$"), y = TeX("$u_2$"), z = TeX("$\\bar{u}$"), color = TeX("$sign(C_D)")) +theme_legend_position(x = "topleft")  + theme(plot.margin=grid::unit(c(0,0,0,0), "mm"))+ theme(text = element_text(size = 18))
plotC_D
ggsave(file.path(figure_folder,"ternaryAll_C_D.png"), plot = plotC_D)




```


```{r ternary Unequal}
#detach("package:plotly", unload = TRUE)
library(ggplot2)
library(ggtern)
library(latex2exp)
library("viridis")
library("ggsci")

datUse = eqDataPos

cols = viridis(6)
plotD <- ggplot(data = datUse, mapping = aes(x = u1eq, y = u2eq, z = bueq)) + coord_tern(Tlim=c(0,1),Llim=c(0,1),Rlim=c(0,1)) + geom_point(aes(colour = D), size = 5, shape = 1) + theme_bw()
plotD <- plotD + tern_limits(labels=c(0,0.2, 0.4, 0.6, 0.8, 1)) + labs(x = TeX("$u_1$"), y = TeX("$u_2$"), z = TeX("$\\bar{u}$"), colour = "D") +theme_legend_position(x = "topleft") + scale_color_viridis() + theme(plot.margin=grid::unit(c(0,0,0,0), "mm"))+ theme(text = element_text(size = 18))
plotD
ggsave(file.path(figure_folder,"ternaryAll_bigD.png"), plot = plotD)

cols = viridis(7)
plotMU <- ggplot(data = datUse, mapping = aes(x = u1eq, y = u2eq, z = bueq)) + coord_tern(Tlim=c(0,1),Llim=c(0,1),Rlim=c(0,1)) + geom_point(aes(colour = mu), size = 3,  shape = 1) + theme_bw()
plotMU <- plotMU + tern_limits(labels=c(0,0.2, 0.4, 0.6, 0.8, 1)) + labs(x = TeX("$u_1$"), y = TeX("$u_2$"), z = TeX("$\\bar{u}$"), colour = TeX("$\\mu$")) +theme_legend_position(x = "topleft") + theme(plot.margin=grid::unit(c(0,0,0,0), "mm"))+ theme(text = element_text(size = 18)) 
plotMU <- plotMU + scale_color_viridis() #scale_colour_manual(values = cols) #scale_color_brewer(palette="viridis") #+ scale_colour_manual(values = c("darkred","red","orange","yellow", "green","blue","darkblue"))
plotMU
ggsave(file.path(figure_folder,"ternaryAllMU.png"), plot = plotMU)

plot_s <- ggplot(data = datUse, mapping = aes(x = u1eq, y = u2eq, z = bueq)) + coord_tern(Tlim=c(0,1),Llim=c(0,1),Rlim=c(0,1))+ geom_point(aes(colour = s), size = 3, shape = 1) + theme_bw()
plot_s <- plot_s + tern_limits(labels=c(0,0.2, 0.4, 0.6, 0.8, 1)) + labs(x = TeX("$u_1$"), y = TeX("$u_2$"), z = TeX("$\\bar{u}$"), colour = 's') +theme_legend_position(x = "topleft") + scale_color_viridis() + theme(plot.margin=grid::unit(c(0,0,0,0), "mm"))+ theme(text = element_text(size = 18))

plot_s
ggsave(file.path(figure_folder,"ternaryAll_K.png"), plot = plot_s)

cols = viridis(5)
plotBeta <- ggplot(data = datUse, mapping = aes(x = u1eq, y = u2eq, z = bueq)) + coord_tern(Tlim=c(0,1),Llim=c(0,1),Rlim=c(0,1))+ geom_point(aes(colour = beta), size = 3, shape = 1) + theme_bw()
plotBeta <- plotBeta + tern_limits(labels=c(0,0.2, 0.4, 0.6, 0.8, 1)) + labs(x = TeX("$u_1$"), y = TeX("$u_2$"), z = TeX("$\\bar{u}$"), colour = TeX("$\\beta$")) + theme_legend_position(x = "topleft") + scale_color_viridis() + theme(plot.margin=grid::unit(c(0,0,0,0), "mm"))+ theme(text = element_text(size = 18))
plotBeta
ggsave(file.path(figure_folder,"ternaryAllbeta.png"), plot = plotBeta)


```