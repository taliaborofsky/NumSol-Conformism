{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supporting Information.\n",
    "Borofsky, T. and Feldman, M. 2020. Static environments with limited resources select for multiple foraging strategies rather than conformity in social learners.\n",
    "# Appendix S2: Solving for Initial Equilibria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from PIL import Image\n",
    "#import sys\n",
    "#sys.path.append('/usr/local/lib/python3.7/site-packages')\n",
    "#import os\n",
    "import numpy as np\n",
    "import importlib\n",
    "from numpy import linalg\n",
    "import helperfuns\n",
    "from helperfuns import *\n",
    "import DatFrameFuns\n",
    "from DatFrameFuns import *\n",
    "import scipy.stats as scs\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "#importlib.reload(helperfuns)\n",
    "import pandas as pd\n",
    "#import sympy as sp\n",
    "#from sympy import *\n",
    "#from sympy.solvers import solve\n",
    "#np.set_printoptions(precision=3, suppress = True)\n",
    "#import seaborn as sns\n",
    "# next two libraries are used to flatten list of lists\n",
    "import functools\n",
    "import operator\n",
    "# for formatting tick labels\n",
    "#from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "#for parallelizing:\n",
    "import multiprocessing as mp\n",
    "from pathos.multiprocessing import ProcessingPool as Pool\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First we set up a parameter mesh, as described in Section 5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "Dvals = np.sort(np.arange(-2,1.2,0.2))\n",
    "svals = np.sort(np.arange(0,4.5,0.5))\n",
    "muvals = np.array([-2, -1, -0.5, -0, 0, 0.5,1,2])\n",
    "betavals = np.arange(0,1.25,0.25)\n",
    "df = get_param_grid(Dvals, svals, muvals, betavals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We use parallelization to to greatly speed up the dataframe generation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Parallelize and find equilibria\n",
    "\n",
    "cores=mp.cpu_count()\n",
    "# split dataframe over cores, stored in df_split\n",
    "df_split = np.array_split(df, cores, axis=0)\n",
    "pool = Pool(cores)\n",
    "\n",
    "# Run get_1side_df over each dataframe in df_split. \n",
    "# get_1side_df iterates 50000 time steps. Stack dataframe (df) parts into one df.\n",
    "\n",
    "df_out = np.vstack(pool.map(get_1side_df, df_split))\n",
    "pool.close()\n",
    "pool.join()\n",
    "pool.clear()\n",
    "df_1side = pd.DataFrame(df_out, columns = df.columns)\n",
    "\n",
    "# fix the column names\n",
    "colnames = ['mu', 'K', 'pc', 's', 'D', 'beta',\n",
    "       'u1init', 'u2init', 'buinit', 'r1init', 'r2init', 'u1eq', 'u2eq',\n",
    "       'bueq', 'r1eq', 'r2eq', 'Weq', 'time', 'reached_eq', 'URstable']\n",
    "df_1side = df_1side[colnames] # gets rid of the added unnamed columns\n",
    "#save to csv\n",
    "df_1side.to_csv('data_1side_1stRound.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the result of the 200,000th iteration to see if it is at equilibrium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_1side = pd.read_csv('data_1side_1stRound.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set error tolerance levels for when I check if the equilibrium fits the equilibrium equation\n",
    "rtol = 1e-10\n",
    "atol = 1e-10\n",
    "\n",
    "# shortening variable names for readability\n",
    "u = 1\n",
    "Weq = df_1side.Weq\n",
    "K = df_1side.K\n",
    "D = df_1side.D\n",
    "pc = df_1side.pc\n",
    "bu = df_1side.bueq\n",
    "u1 = df_1side.u1eq\n",
    "u2 = df_1side.u2eq\n",
    "r1 = df_1side.r1eq\n",
    "r2 = df_1side.r2eq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# These are the recursion systems when u = 1 (only AB foragers) at equilibrium\n",
    "should0_u1 = Weq*u1 - u*(K*(u1 + D*phi_fun(u1)) + pc)*(1+r1)\n",
    "should0_u2 = Weq*u2 - u*(K*(u2 + D*phi_fun(u2)) + pc)*(1+r2)\n",
    "should0_bu = Weq*bu - u*(K*(1 - u1 - u2 - D*phi_fun(u1) - D*phi_fun(u2)) + 1-K - pc)\n",
    "\n",
    "reached_eq = np.isclose(should0_u1,0,rtol=rtol, atol = atol)\n",
    "reached_eq = reached_eq & np.isclose(should0_u2,0,rtol=rtol, atol = atol)\n",
    "reached_eq = reached_eq & np.isclose(should0_bu,0,rtol=rtol, atol = atol)\n",
    "\n",
    "df_1side.reached_eq = reached_eq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate those that reached equilibrium from those that did not\n",
    "df_correct = df_1side.query('reached_eq==True')\n",
    "df_fail = df_1side.query('reached_eq==False')\n",
    "len(df_fail)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We see that 255 did not reach equilibrium in 200000 steps. For each of these, $\\beta = 0$, $D = 0$, and $\\pi_{C} < 1 \\times 10^{-5}$ but $\\pi_{C} \\neq 0$. Also, for these $K > 1/2$ (shown in the cells below). We showed in S4.3 that equilibria with these parameters are internally unstable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df_fail.beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.69145906, 0.84134446, 0.93319278, 0.9772182 , 0.97724987,\n",
       "       0.99378694, 0.99861843, 0.99864982, 0.99976397, 0.99993666])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df_fail.s)\n",
    "np.unique(df_fail.K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.4408921e-16])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df_fail.D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.86587700e-10, 1.89895625e-08, 2.86651572e-07, 3.39767312e-06,\n",
       "       3.16712418e-05])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df_fail.pc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now try to fill in rows that didn't reach equilibrium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/software/user/open/py-pandas/0.23.0_py36/lib/python3.6/site-packages/pandas/core/generic.py:4401: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "df_fail.time = -1 # so I know these were not iterated to equilibrium and thus are not internally stable.\n",
    "# from scipy.optimize import fsolve\n",
    "df_fixed = fsolve_failed_eq(df_fail)\n",
    "\n",
    "df_1side = df_correct.append(df_fixed)\n",
    "#df_1side.to_csv('data_1side_fixed.csv')\n",
    "df_1side.to_csv('data_1side_fixed.csv')\n",
    "\n",
    "# reflect equilibria in the manner described in the Numerical Analysis, equations 24 - 25.\n",
    "df_total = reflect_df(df_1side)\n",
    "\n",
    "# make it look good.\n",
    "df = df_total.sort_values(by=['mu','beta','s','D'])\n",
    "df.reset_index(inplace=True, drop=True) \n",
    "df = df[colnames]\n",
    "# There's an issue with setting D = 0. I'm getting weird python e-16 values instead. \n",
    "# This can make code difficult later on, so I'm rounding it now\n",
    "df.D = df['D'].round(6)\n",
    "# We want later to be able to count how many times iteration failed for each equilibrium\n",
    "df['iterated'] = df.time!= -1\n",
    "df.to_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_UniqueEquilibria(df,if_save=False):\n",
    "    df_eq = df.round(6)[(df.reached_eq==1)&(df.iterated==1)].groupby(['K','pc','s','mu','D','beta','u1eq','u2eq','bueq',\n",
    "                                                     'r1eq','r2eq','Weq','URstable'], as_index = False)\n",
    "    df_eq = df_eq['u2init'].count()\n",
    "    df_eq.rename(columns={'u2init':'NumInitials'}, inplace=True)\n",
    "    # df_eq.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    df_eq = df_eq.apply(lambda row: JstarStable(row), axis = 1) # This step was removed because \n",
    "                                                                  # we are only working with equilibria \n",
    "                                                                  # which were reached through iteration\n",
    "    df_eq = get_gradients(df_eq)\n",
    "    if if_save:\n",
    "        df_eq.to_csv('UniqueEquilibria.csv', index = False)\n",
    "    return(df_eq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We have a lot of repeat equilibria in the dataframe df because many of the initial points go to the same equilibrium.\n",
    "# We now extract the unique equilibria for each parameter combination.\n",
    "df = pd.read_csv('data.csv')\n",
    "df_main = df[(df.reached_eq==1)&(df.iterated==1)]\n",
    "unique_eq = get_UniqueEquilibria(df_main)\n",
    "diff = np.abs(unique_eq.u1eq - unique_eq.u2eq)\n",
    "unique_eq['difference'] = diff\n",
    "unique_eq.to_csv('UniqueEquilibriaDF.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Stability\n",
    "\n",
    "It helps to have columns documenting which alleles can invade. These columns are x_pos_invades, x_neg_invades, D_pos_invades, and D_neg_invades:\n",
    "- x_pos_invades = TRUE if $C_s > 0$ and $K < 1$. Else false\n",
    "- x_neg_invades = TRUE if $C_s < 0$ and $K > 0$. Else false\n",
    "- D_pos_invades = TRUE if $C_D > 0$ and $D < 1$. Else false\n",
    "- D_neg_invades = TRUE if $C_D < 0$ and $D > -2$  \n",
    "There are many cases of $C_D = 0$ that need to be resolved. There are no cases of $C_s = 0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_eq['x_pos_invades'] = unique_eq.C_s > 0\n",
    "\n",
    "\n",
    "unique_eq['x_neg_invades'] = unique_eq.C_s < 0\n",
    "unique_eq.loc[unique_eq.K == 0, 'x_neg_invades'] = False\n",
    "\n",
    "unique_eq['y_pos_invades'] = unique_eq.C_D > 0\n",
    "unique_eq.loc[unique_eq.D == 1, 'y_pos_invades'] = False\n",
    "\n",
    "unique_eq['y_neg_invades'] = unique_eq.C_D < 0\n",
    "unique_eq.loc[unique_eq.D == -2, 'y_neg_invades'] = False\n",
    "\n",
    "unique_eq.to_csv('UniqueEquilibriaDF.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unique_eq = pd.read_csv('UniqueEquilibriaDF.csv')\n",
    "cores=mp.cpu_count()\n",
    "df_split = np.array_split(unique_eq, cores, axis=0)\n",
    "pool = Pool(cores)\n",
    "df_out = np.vstack(pool.map(df_ext_stability_iterate, df_split))\n",
    "pool.close()\n",
    "pool.join()\n",
    "pool.clear()\n",
    "cols =  df_check.columns\n",
    "df_fixed = pd.DataFrame(df_out, columns = cols)\n",
    "\n",
    "df_fixed.to_csv('UniqueEquilibriaDF_fixed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "cols = df.columns\n",
    "df_normal = df.query('C_D!=0')\n",
    "df_weird = df.query('C_D==0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['s', 'D', 'mu', 'beta', 'K', 'pc'], dtype='object')] are in the [index]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.9/site-packages/multiprocess/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n  File \"/usr/local/lib/python3.9/site-packages/multiprocess/pool.py\", line 48, in mapstar\n    return list(map(*args))\n  File \"/usr/local/lib/python3.9/site-packages/pathos/helpers/mp_helper.py\", line 15, in <lambda>\n    func = lambda args: f(*args)\n  File \"/Users/taliaborofsky/Documents/Stanford/Research/Feldman/Ecology of Learning/Conformism/NumSol/DatFrameFuns.py\", line 232, in df_ext_stability_iterate\n    x_pos_invades = df.apply(lambda row_eq:Check_ext_stability_iterate(row_eq, 0.01, 0)) # ds > 0\n  File \"/usr/local/lib/python3.9/site-packages/pandas/core/frame.py\", line 7768, in apply\n    return op.get_result()\n  File \"/usr/local/lib/python3.9/site-packages/pandas/core/apply.py\", line 185, in get_result\n    return self.apply_standard()\n  File \"/usr/local/lib/python3.9/site-packages/pandas/core/apply.py\", line 276, in apply_standard\n    results, res_index = self.apply_series_generator()\n  File \"/usr/local/lib/python3.9/site-packages/pandas/core/apply.py\", line 290, in apply_series_generator\n    results[i] = self.f(v)\n  File \"/Users/taliaborofsky/Documents/Stanford/Research/Feldman/Ecology of Learning/Conformism/NumSol/DatFrameFuns.py\", line 232, in <lambda>\n    x_pos_invades = df.apply(lambda row_eq:Check_ext_stability_iterate(row_eq, 0.01, 0)) # ds > 0\n  File \"/Users/taliaborofsky/Documents/Stanford/Research/Feldman/Ecology of Learning/Conformism/NumSol/DatFrameFuns.py\", line 248, in Check_ext_stability_iterate\n    s, D, mu, beta, K, pc = np.transpose(*row_eq[['s','D','mu','beta','K','pc']].values)\n  File \"/usr/local/lib/python3.9/site-packages/pandas/core/series.py\", line 877, in __getitem__\n    return self._get_with(key)\n  File \"/usr/local/lib/python3.9/site-packages/pandas/core/series.py\", line 917, in _get_with\n    return self.loc[key]\n  File \"/usr/local/lib/python3.9/site-packages/pandas/core/indexing.py\", line 895, in __getitem__\n    return self._getitem_axis(maybe_callable, axis=axis)\n  File \"/usr/local/lib/python3.9/site-packages/pandas/core/indexing.py\", line 1113, in _getitem_axis\n    return self._getitem_iterable(key, axis=axis)\n  File \"/usr/local/lib/python3.9/site-packages/pandas/core/indexing.py\", line 1053, in _getitem_iterable\n    keyarr, indexer = self._get_listlike_indexer(key, axis, raise_missing=False)\n  File \"/usr/local/lib/python3.9/site-packages/pandas/core/indexing.py\", line 1266, in _get_listlike_indexer\n    self._validate_read_indexer(keyarr, indexer, axis, raise_missing=raise_missing)\n  File \"/usr/local/lib/python3.9/site-packages/pandas/core/indexing.py\", line 1308, in _validate_read_indexer\n    raise KeyError(f\"None of [{key}] are in the [{axis_name}]\")\nKeyError: \"None of [Index(['s', 'D', 'mu', 'beta', 'K', 'pc'], dtype='object')] are in the [index]\"\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-58eb40fb678e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_weird\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdf_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_ext_stability_iterate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_split\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/pathos/multiprocessing.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, f, *args, **kwds)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mAbstractWorkerPool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_AbstractWorkerPool__map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0m_pool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_serve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_pool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# chunksize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m     \u001b[0mmap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAbstractWorkerPool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mimap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/multiprocess/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         '''\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/multiprocess/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    769\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['s', 'D', 'mu', 'beta', 'K', 'pc'], dtype='object')] are in the [index]\""
     ]
    }
   ],
   "source": [
    "unique_eq = pd.read_csv('UniqueEquilibriaDF.csv')\n",
    "df_weird = unique_eq.head()\n",
    "cores=mp.cpu_count()\n",
    "df_split = np.array_split(df_weird, cores, axis=0)\n",
    "pool = Pool(cores)\n",
    "df_out = np.vstack(pool.map(df_ext_stability_iterate, df_split))\n",
    "pool.close()\n",
    "pool.join()\n",
    "pool.clear()\n",
    "df_fixed = pd.DataFrame(df_out, columns = cols) # restoring original column names\n",
    "#df_total = df_normal.append(df_fixed)\n",
    "#df_total.to_csv('UniqueEquilibriaDF.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' A better way to check stability'''\n",
    "\n",
    "cores=mp.cpu_count()\n",
    "df_split = np.array_split(df_weird, cores, axis=0)\n",
    "pool = Pool(cores)\n",
    "df_out = np.vstack(pool.map(get_stable_check, df_split))\n",
    "pool.close()\n",
    "pool.join()\n",
    "pool.clear()\n",
    "df_fixed = pd.DataFrame(df_out, columns = cols) # restoring original column names\n",
    "df_total = df_normal.append(df_fixed)\n",
    "df_total.to_csv('UniqueEquilibriaDF.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next, go to SensitivityAnalysis.Rmd to see analysis of these equilibria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No longer used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-3619a1b5057e>, line 55)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-3619a1b5057e>\"\u001b[0;36m, line \u001b[0;32m55\u001b[0m\n\u001b[0;31m    dy1vec = np.array([0.05, 0.3,0.0.08])*dy\u001b[0m\n\u001b[0m                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def Check_Stable_D(row):\n",
    "# We have a bunch of points with C_D = 0. Check_Stable_D checks if they're actually stable\n",
    "\n",
    "    row = row.copy() # explicitly tell python i'm making a copy so i don't get the warning\n",
    "    \n",
    "    # get vectors of post perturb values of all the frequencies\n",
    "    umat,ymat,rmat = Perturb(row) # Perturb is a function defined below\n",
    "    umat = np.array(umat); ymat = np.array(ymat); rmat = np.array(rmat)\n",
    "    # check stability to increase in D\n",
    "    \n",
    "    dD =  0.01\n",
    "    n = len(umat[0]) \n",
    "    y_pos_invades = False # default is that it is stable\n",
    "    if row.D <= 0.99: # because if D >= 0.99 then dD \\geq 0.01 can't invade\n",
    "        for i in range(0,n):\n",
    "            result = NextGen(umat[:,i],[0,0,0],ymat[:,i],rmat[:,i], \n",
    "                             row.D, row.K,row.pc,row.beta,\n",
    "                             deltas = [dD, 0, 0], eta=1)\n",
    "            yvec = result[2]\n",
    "            y = sum(yvec)\n",
    "            if y > 0.01: # asking: after 1 iteration, does y increase?\n",
    "                y_pos_invades = True\n",
    "                break\n",
    "    # We don't need to worry about cases of 0.99 < D < 1 because I don't have any of those\n",
    "    \n",
    "    dD = -0.01\n",
    "    y_neg_invades = False # default is that it is stable\n",
    "    #check stability to decrease in D\n",
    "    if row.D >= -1.99: # otherwise it's stable because D can't go down further\n",
    "        for i in range(0,n):\n",
    "            result = NextGen(umat[:,i],[0,0,0],ymat[:,i],rmat[:,i], \n",
    "                             row.D, row.K,row.pc,row.beta,\n",
    "                             deltas = [dD, 0, 0], eta=1)\n",
    "            yvec = result[2]\n",
    "            y = sum(yvec)\n",
    "            if y > 0.01: \n",
    "                y_neg_invades = True \n",
    "                break\n",
    "    \n",
    "    row.loc['y_pos_invades'] = y_pos_invades\n",
    "    row.loc['y_neg_invades'] = y_neg_invades\n",
    "    return(row)\n",
    "\n",
    "def Perturb(row):\n",
    "# After the [u1,u2,bu,r1,r2] eq is perturbed with the addition of the a or b allele, get new frequencies\n",
    "# perturb by a magnitude of 0.01... so |dr1| = |dr2| = |du| = 0.01, and either |dx| or |dy| = 0.01\n",
    "\n",
    "    # use dyvec here but dxvec could work too\n",
    "    uvec = [row.u1eq, row.u2eq, row.bueq]\n",
    "    rvec = [row.r1eq, row.r2eq]\n",
    "    # get new post-perturb vectors\n",
    "    \n",
    "    # no need to check if valid\n",
    "    dy = 0.01\n",
    "    dy1vec = np.array([0.05, 0.3,0.48, 0.08])*dy\n",
    "    dy2vec = np.array([0.1,0.6,0.9])*dy\n",
    "    dbyvec = dy - dy1vec - dy2vec\n",
    "    which_y = [0,1,2,3]\n",
    "    \n",
    "    #dr... prune r + dr values that are invalid\n",
    "    \n",
    "    dr1=0 #the default is not changing r1\n",
    "    if rvec[0]>0:\n",
    "        dr1 = np.array([-0.01,0.01])\n",
    "        check_r1 = (rvec[0] + dr1 > 0)&(rvec[0] + dr1 < 1)\n",
    "        dr1 = dr1[check_r1]\n",
    "    dr2 = 0\n",
    "    if rvec[1]>0:\n",
    "        dr2 = np.array([-0.01,0.01])\n",
    "        check_r2 = (rvec[1] + dr2 > 0) & (rvec[1] + dr2 < 1)\n",
    "        dr2 = dr2[check_r2]\n",
    "    \n",
    "    # du perturbations... look similar to x perturbs, but opposite direction\n",
    "    du = -dy\n",
    "    du1vec = np.array([0.015, 0.29,0.49, 0.07])*du\n",
    "    du2vec = np.array([0.11,0.49,0.51,0.89])*du\n",
    "    dbuvec = du - du1vec - du2vec\n",
    "    which_u = [0,1,2,3]\n",
    "    for i in which_u:\n",
    "        duvec = [du1vec[i],du2vec[i],dbuvec[i]]\n",
    "        [du1vec[i],du2vec[i],dbuvec[i]] = Perturb_EdgeCase(uvec,duvec)\n",
    "    \n",
    "    # now find all the combinations\n",
    "    which_y_mesh, which_u_mesh, DR1, DR2 = np.meshgrid(which_y, which_u, dr1, dr2)\n",
    "    [which_y, which_u, dr1, dr2] = [np.ndarray.flatten(item) for \n",
    "                                    item in [which_y_mesh, which_u_mesh, DR1, DR2]]\n",
    "    y1 = dy1vec[which_y]; y2 = dy2vec[which_y]; by = dbyvec[which_y]\n",
    "    u1 = uvec[0] + du1vec[which_u]\n",
    "    u2 = uvec[1] + du2vec[which_u]\n",
    "    bu = uvec[2] + dbuvec[which_u]\n",
    "    r1 = rvec[0] + dr1\n",
    "    r2 = rvec[1] + dr2\n",
    "    \n",
    "    \n",
    "    return([u1,u2,bu],[y1,y2,by],[r1,r2])\n",
    "\n",
    "def Perturb_EdgeCase(uvec,duvec):\n",
    "    #recursively checks for edge cases so i don't get an invalid frequency. Adjusts duvec if needed\n",
    "    \n",
    "    # make sure using numpy arrays\n",
    "    du = sum(duvec)\n",
    "    uvec = np.array(uvec); duvec = np.array(duvec);\n",
    "    # find locations of edge cases\n",
    "    edge_bool = uvec + duvec <= 0\n",
    "    \n",
    "    n = sum(edge_bool)\n",
    "    if n>0:\n",
    "        duvec[edge_bool] = -uvec[edge_bool] +0.00001 # so not at exactly 0\n",
    "        du_remain = du - sum(duvec)\n",
    "        duvec[~edge_bool] = duvec[~edge_bool] + (1/np.float64(3-n))*du_remain\n",
    "        \n",
    "        # make sure that we didn't cause a different frequency to be negative:\n",
    "        return(Perturb_EdgeCase(uvec,duvec))\n",
    "\n",
    "    else:\n",
    "        return(duvec)\n",
    "\n",
    "\n",
    "def get_stable_check(df):\n",
    "    # this function is just a wrapper to be used with pool.map that takes a dataframe as an input and\n",
    "    # runs Check_Stable_D over the data frame\n",
    "    df = df.apply(lambda row: Check_Stable_D(row), axis = 1)\n",
    "    return(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
